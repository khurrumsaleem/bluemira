base
====

Serialization
-------------

:py:class:`BLUEPRINT.reactor.Reactor` objects can be serialized and deserialized using
the :py:meth:`BLUEPRINT.reactor.Reactor.save` and :py:meth:`BLUEPRINT.reactor.Reactor.load`
methods. Under the hood they use
`pickle <https://docs.python.org/3/library/pickle.html>`_.

Not all of the attributes of a `Reactor` can be serialized. After loading you may need to
call again the following methods:

* `run_PROCESS`
* `build_neutronics_model`
* `build_cad`

An example of serializing and de-serializing a reactor object to a file:

.. code-block:: pycon

    >>> R = SingleNullReactor(Config, Build_Config, Build_Tweaks)
    >>> R.build()
    >>> R.save('reactor.pkl')
    >>> R2 = SingleNullReactor.load('reactor.pkl')

The `save` method will automatically create a pickle for you if you don't specify a path. `save` returns the path to
the persisted reactor:

.. code-block:: pycon

    >>> R = SingleNullReactor(Config, Build_Config, Build_Tweaks)
    >>> R.build()
    >>> path = R.save()
    >>> R2 = SingleNullReactor.load(path)


.. warning::

    pickle is not a secure protocol and unpickling untrusted objects can result in code execution,
    which is a security vulnerability.

.. note::

    `Reactor` classes are intended to have one instance per class. When a reactor is
    loaded the :py:class:`BLUEPRINT.base.parameter.ParameterFrame` on the reactor class is replaced with the loaded
    one.

    `Reactor` classes are stored in a registry on creation, so every `Reactor` must have a unique name. The right class
    must exist (either having been recreated or imported) before loading.

You can also directly `pickle` and `unpickle` Reactor objects directly:

.. code-block:: pycon

   >>> import pickle
   >>> R = SingleNullReactor(Config, Build_Config, Build_Tweaks)
   >>> R.build()
   >>> with open('reactor.pkl', 'wb') as f:
   ...     pickle.dump(f, reactor)
   ...
   >>> with open('reactor.pkl', 'rb') as f:
   ...     R = pickle.load(f)
   ...
   >>>

Absolute & Relative Paths
-------------------------

`Reactor` class instances have two paths specified in `Build_Config`:

* `reference_data_root` is used to store working data during the run.
* `generated_data_root` is used to store output data generated by the run.

These paths may be absolute, or they may be relative to the BLUEPRINT root folder by prefixing
the keyword ``!BP_ROOT!``. When the `Reactor` class is instantiated, the keyword will
be replaced with the path to BLUEPRINT root for the current system.

For example:

.. code-block:: pycon

    >>> Build_Config = {
            "reference_data_root": "!BP_ROOT!/data",
            "generated_data_root": "!BP_ROOT!/generated_data",
        }

Type-checking
-------------

A type-checking framework is available to help in development. Checks are carried out at runtimes and will raise a :py:class:`BLUEPRINT.typebase.TypeFrameworkError` if the specified types are not those expected.

The framework uses Python annotations and the :py:mod:`typing` module to enforce types.

.. code-block:: python

    from typing import Type, List
    from BLUEPRINT.systems.baseclass import ReactorSystem
    from BLUEPRINT.geometry.loop import Loop

    class Example(ReactorSystem):
        a: str
        b: List[float]
        c: Type[Loop]

        def __init__(self, a: str, b: List[float], c: Type[Loop], d: int):
            self.a = a
            self.b = b
            self.c = c
            self.d = d

        def do_something(self, e: float) -> Type[Loop]:
            return self.c.offset(self.b[0]+self.d+e)

If we try to violate these type specifications, we get an error:

.. code-block:: pycon

   >>> E = Example('test', [5.6, 5], Loop([4, 5, 6], [6, 7, 8]), 4)
   >>> BLUEPRINT.base.typebase.TypeFrameworkError: Error in module: __main__
       function: __init__

       was expecting argument 'b'=[5.6, 5] to be of type 'typing.List[float]'

   >>> E = Example('test', [5.6, 5.], Loop([4, 5, 6], [6, 7, 8]), 4)
   ... E.do_something(4)
   >>> BLUEPRINT.base.typebase.TypeFrameworkError: Error in module: __main__
       function: do_something
       was expecting argument 'e'=4 to be of type '<class 'float'>'

The type-checking functionality has a global on/off switch: :py:const:`ENGAGE_TYPECHECKING` in :py:mod:`BLUEPRINT.base.typebase`.

If functions annotations are not used in a function or class, type-checking is not implemented.

Parameters and ParameterFrames
------------------------------

Parameter class
^^^^^^^^^^^^^^^


The Parameter class uses a :py:class:`wrapt.ObjectProxy` to make all access to a Parameter act as if it is the same type as the value of Parameter (except where required).
There are a few extra builtin methods to enable copying, array manipulation and pickling.
A Parameter has a source history and a value history which are updated on a change to source or value.

If the source is not provided for a Parameter a warning will be produced.

.. code-block:: python

    p = Parameter(var='var', name='variable', value=5.0)

    print(p)  # var = 5.0 (variable)

    isinstance(p, float)  # True

    a = p + 5  # a = 10.0

    p += 5

    print(p)  # var = 10.0 (variable)

Idioms of the Parameter class
"""""""""""""""""""""""""""""

For very low types (eg `str`) it is not possible to modify how an object is treated:

.. code-block:: python

    p = Parameter(var='var', name='var', value='hello')

    print(p)  # 'hello'

    isinstance(p, str)  # True

    repr(p)          # 'hello'
    str.__repr__(p)  # TypeError

    p.join('world')  # 'helloworld'

    ''.join(p, 'world') # TypeError

    ''.join(p.value, 'world') # 'helloworld'


This only affects some situations, the usual culprit is when leaving python for C. So far this comes down to internal use of :py:func:`__repr__` for example :py:func:`float.__repr__` or :py:func:`str.__repr__` for type checking. As a general rule :py:func:`__repr__` shouldn't be used for type checking anyway but occasionally is internally in python.

ParameterFrame class
^^^^^^^^^^^^^^^^^^^^

The ParameterFrame class follows the 'borg' pattern where state is passed round (on request) but each instance is not the same (therefore not a singleton).
The default state of the frame is stored in :py:attr:`__default_params` and populated with the :py:meth:`set_default_parameters` classmethod.

In turn the default state can then populate :py:attr:`__dict__` (as a copy, but this could be in future be changed to a per reactor class variable).
To update the default Parameter values globally :py:meth:`_force_update_default` can be used which updates the Parameter in all ParameterFrame instances as well as the ParameterFrame class.

The attributes of a ParameterFrame are Parameter objects but the value of the Parameter can be accessed directly as a dictionary or with the `value` attribute as with a singular Parameter.

If a ParameterFrame.param is set to a 2 element tuple the second element is assumed to be its source if it is set to a Parameter (with the same name ONLY) the value and source are taken only.
A dictionary of :py:data:`{"value": .., "source":..}` can also be provided.:

.. code-block:: python

    pf = ParameterFrame(config)
    pf.attr = (1., 'here')
    pf.attr = Parameter(var='attr', name='attr', value=1.)
    pf.attr = {"value":1., "source": 'here'}

The concise json representation returns :py:data:`{"value": .., "source":..}` of each Parameter and the verbose representation returns all the attributes of the Parameter.
